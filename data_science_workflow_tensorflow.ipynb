{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Use Classification using TensorFlow Transfer Learning\n",
    "In this notebook, we illustrate how one can produce a deep learning model to classify aerial images based on land use type (developed, forested, cultivated, etc.). We apply transfer learning with MicrosoftML to adapt a pretrained featurizer for our classification use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"prep\"></a>\n",
    "## Prepare deep learning framework-specific input files\n",
    "\n",
    "If you have not generated your own training and validation sets through image extraction, download the following files and decompress them in your VM's temporary (`D:\\`) storage:\n",
    "- [Balanced training image set (~3 GB)](https://mawahstorage.blob.core.windows.net/aerialimageclassification/imagesets/balanced_training_set.zip)\n",
    "- [Balanced validation image set (~1 GB)](https://mawahstorage.blob.core.windows.net/aerialimageclassification/imagesets/balanced_validation_set.zip)\n",
    "\n",
    "The image sets linked above contain raw PNG images sorted into folders by their assigned label. Many deep learning frameworks require proprietary image formats or supporting files to efficiently load images in minibatches for training. We now produce the supporting files needed by our CNTK and TensorFlow training scripts. Note that we do not need to produce similar supporting files for the validation image set, because we will not use minibatching when applying the trained models to the validation set.\n",
    "\n",
    "Update the `training_image_dir` variable below to reflect the directory where your training and validation sets have been saved. The `label_to_number_dict` variable specifies the correspondence between the label names and a numeric code; it does not need to be modified unless you have changed the labeling scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from land_use.retrain import retrain\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import land_use.connection_settings as cs\n",
    "import land_use.land_use_classification_utils as luc\n",
    "\n",
    "repo_dir = cs.REPO_DIR\n",
    "image_dir = cs.IMAGE_DIR\n",
    "label_to_number_dict = cs.LABELS\n",
    "\n",
    "# Autoreload when modules are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Show matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"tf\"></a>\n",
    "### TensorFlow\n",
    "\n",
    "We made use of the [`tf-slim` API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) for TensorFlow, which provides pre-trained ResNet models and helpful scripts for retraining and scoring. These scripts require converting the image set into [TFRecords](https://www.tensorflow.org/how_tos/reading_data/#file_formats) for minibatching. (Each TFRecord contains many image files as well as their labels.) We also create a `labels.txt` file mapping the labels to integer values, and a `dataset_split_info.csv` file describing the images assigned to the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44184 training images\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5318)\n",
    "\n",
    "training_image_dir = os.path.join(cs.IMAGE_DIR, \"TrainData\")\n",
    "training_filenames = luc.find_images(training_image_dir)\n",
    "training_filenames = np.random.permutation(training_filenames)\n",
    "df = luc.write_dataset('aerial', 'train', training_filenames, training_image_dir, n_shards=50)\n",
    "df.to_csv(os.path.join(training_image_dir, 'dataset_split_info.csv'), index=False)\n",
    "\n",
    "with open(os.path.join(training_image_dir, 'labels.txt'), 'w') as f:\n",
    "    for key, value in label_to_number_dict.items():\n",
    "        f.write('{}:{}\\n'.format(key, value))\n",
    "        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name=\"tensorflow\"></a>\n",
    "## Retrain a pretrained ResNet with TensorFlow\n",
    "\n",
    "We made use of the [`tf-slim` API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) for TensorFlow, which provides pre-trained ResNet models and helpful scripts for retraining and scoring. During training set preparation, we created the [TFRecords](https://www.tensorflow.org/how_tos/reading_data/#file_formats) that the training script will use as input. For more details on the training data, please see the image preparation notebook in the [Embarrassingly Parallel Image Classification](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification) repository. \n",
    "\n",
    "Our retraining file, `retrain.py` in the `tf` folder of [this repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification), is a modified version of `train_image_classifier.py` from the [TensorFlow models repo's slim subdirectory](https://github.com/tensorflow/models/tree/master/slim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you have run [download_tf_models.py](utils/download_tf_models.py) prior to retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\t-tyrome\\Documents\\Internship\\LandUseClassification\\land_use\\retrain.py:229: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\t-tyrome\\Documents\\Internship\\LandUseClassification\\land_use\\retrain.py:229: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\temp\\sqlserver\\xcopy installs\\14.0.900.75\\retail\\amd64\\sqlservr\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\temp\\sqlserver\\xcopy installs\\14.0.900.75\\retail\\amd64\\sqlservr\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\temp\\sqlserver\\xcopy installs\\14.0.900.75\\retail\\amd64\\sqlservr\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:151: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\temp\\sqlserver\\xcopy installs\\14.0.900.75\\retail\\amd64\\sqlservr\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\contrib\\losses\\python\\losses\\loss_ops.py:151: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from \\\\Tyler-laptop\\tylersqlserver\\FileTableData\\TFRetrainCheckpoints\\model.ckpt-57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from \\\\Tyler-laptop\\tylersqlserver\\FileTableData\\TFRetrainCheckpoints\\model.ckpt-57\n"
     ]
    }
   ],
   "source": [
    "train_data = os.path.join(cs.IMAGE_DIR, 'TrainData')\n",
    "train_dir = os.path.join(cs.IMAGE_DIR, \"TFRetrainCheckpoints\")\n",
    "\n",
    "# Retrain the model. This can take hours.\n",
    "retrain(train_data, train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(cs.IMAGE_DIR, \"ValData\")\n",
    "file_list = glob.glob('{}/*/*.png'.format(dataset_dir))\n",
    "\n",
    "start = pd.datetime.now()\n",
    "results_tf = luc.score_model(file_list)\n",
    "print('Scored {} images'.format(len(results_tf)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame(results_tf, columns=['filename', 'true_label', 'predicted_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred = np.array(tf_df['predicted_label'])\n",
    "y_true = np.array(tf_df['true_label'])\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "luc.plot_confusion_matrix(cm, [\"Barren\", \"Forest\", \"Shrub\", \"Cultivated\", \"Herbaceous\", \"Developed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy (all classes)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy (all classes): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy (Undeveloped, Cultivated, Developed)\n",
    "y_true = luc.merge_classes(y_true)\n",
    "y_pred = luc.merge_classes(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy (Undeveloped, Cultivated, Developed): \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Score on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(cs.IMAGE_DIR, \"TestData\")\n",
    "file_list = glob.glob('{}/*/*.png'.format(dataset_dir))\n",
    "\n",
    "start = pd.datetime.now()\n",
    "results_tf = luc.score_model(file_list)\n",
    "print('Scored {} images'.format(len(results_tf)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame(results_tf, columns=['filename', 'true_label', 'predicted_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred = np.array(tf_df['predicted_label'])\n",
    "y_true = np.array(tf_df['true_label'])\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "luc.plot_confusion_matrix(cm, [\"Barren\", \"Forest\", \"Shrub\", \"Cultivated\", \"Herbaceous\", \"Developed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy (all classes)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy (all classes): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy (Undeveloped, Cultivated, Developed)\n",
    "y_true = luc.merge_classes(y_true)\n",
    "y_pred = luc.merge_classes(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy (Undeveloped, Cultivated, Developed): \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
